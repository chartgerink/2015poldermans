---
title: "Analyzing DECREASE trials for extent of data fabrication [working title]"
author: "Chris HJ Hartgerink, Gerben ter Riet, Marleen Kemper"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  pdf_document:
    fig_caption: yes
    keep_tex: yes
  html_document: default
  word_document: default
csl: ../bibliography/ama.csl
bibliography: ../bibliography/library.bib
---

The effect of beta-blockers on perioperative mortality in non-cardiac surgery has been controversial [@Coleg5210] due to findings of research  misconduct in two related clinical trials  [@poldermans1999;@dunkelgrun2009;@commissie2011;@commissie2012;@commissie2013]. Three meta-analyses that included the trials subject to research misconduct concluded that beta-blockers decrease perioperative mortality [@Devereaux313;@Angeli2010;@bouri2014] whereas a meta-analysis that excluded the suspect trials concluded that beta-blockers increase perioperative mortality [@bouri2014]. In these studies, perioperative mortality was defined as the deathrate of patients during the period of the surgical procedure, which typically includes admission, anaesthesia, surgery, and recovery. 

The trials subject to research misconduct were the Dutch DECREASE-I and DECREASE-IV trials [@commissie2011;@commissie2012;@commissie2013]. The committees that investigated the integrity of the DECREASE trials reported that data fabrication was likely but that the extent of the data fabrication remained unclear [@commissie2011;@commissie2012;@commissie2013]. Moreover, the latest guidelines still recommend the usage of beta-blockers in the perioperative period in certain cases [@esc2014;@Fleishere278]. Considering these consequences, we aim to estimate the extent of data fabrication in the DECREASE studies [@poldermans1999;@dunkelgrun2009;@commissie2011;@commissie2012;@commissie2013] to further the debate on using beta-blockers in the perioperative period of CAD patients undergoing non-cardiac surgery. 

The reports on the integrity of the DECREASE trials primarily focused on the provenance of the raw data but did not investigate the extent to which the DECREASE trials deviated from comparable trials. The provenance is primarily concerned with the origins of the data, verifying things such as (but not limited to) the informed consent and whether data corresponded to patient files. The committee reports did not neglect statistical evaluation however: a statistical expert evaluated the applicability of forensic statistical methods [@commissie2013] to evaluate results of trials separately (i.e., DECREASE-I, DECREASE-IV). Nonetheless, comparing across trials is a method that has previously been used to monitor trial data quality or to test for potential data anomalies [@Buyse1999-jq]. Moreover, this method has previously proven to be effective in detecting data fabrication [@Knepper2016-la]. Comparing the DECREASE trials to other published trials studying the effectiveness of beta-blockers with respect to perioperative mortality could prove informative of the potential extent of the fabrication in the DECREASE trials.

The effectiveness of perioperative beta-blockade is obfuscated by the afflicted DECREASE trials, potentially interacting with the type of beta-blocker and the way that beta-blocker was administered (i.e., dose and duration of treatment).  Throughout the clinical trials regarding beta-blockers, patients were administered various beta-blockers (e.g., metroprolol, bisoprolol, atenolol) and in various ways (e.g., intraveneously, orally; half an hour before surgery or multiple days before surgery). Factors such as dosage and duration can have an effect on the pharmacological effectiveness with respect to perioperative mortality. Moreover, the anomalous results from the DECREASE trials might partly be caused by such differences [@klei2015] and not purely due to data fabrication (given not all data points can be considered fabricated at this point).

The latest guidelines of the European Society of Cardiology and the American Heart Association still recommend the usage of beta-blockers in certain cases [@;@]. Therefore, we evaluate the usage of beta-blockers with respect to its effectiveness for the the perioperative period in patients undergoing non-cardiac surgery. First, we estimated the extent of data fabrication in the DECREASE studies [@poldermans1999;@dunkelgrun2009] Secondly, we evaluated the clinical studies used in the different meta-analysis from a pharmacological point of view. 

# Part 1: statistical estimation of data fabrication in DECREASE trials

To statistically investigate the evidence of data fabrication in the DECREASE studies [@dunkelgrun2009;@poldermans1999], we took three steps. First, we reproduced the findings from the 2014  meta-analysis by Bouri et al. [@bouri2014] that contained sufficient information to estimate the deviation of the DECREASE trials from other published trials on beta-blockers. We also include type of beta-blocker to inspect whether this is predictive of the effect of beta-blockers on perioperative mortality. Second, we evaluated the probability that the DECREASE trials occurred assuming no data fabrication. Third, we reversed this assumption and assumed that data fabrication did occur and estimated how many data points would have to be fabricated to reproduce the results of the DECREASE trials, if the other published trials are regarded as estimating the true effect of beta-blockers on perioperative mortality in patients undergoing non-cardiac surgery.

## Step 1: reproducing meta-analysis of Bouri et al. (2014)

### Methods

To ensure that we used similar analysis procedures as in the 2014 meta-analysis [@bouri2014], we initially reproduced Bouri et al.'s estimates. This ensured that (1) their results are reproducible and (2) we are using the correct estimates in subsequent steps of our analyses. Using figures 2 and 3 from the original paper [@bouri2014], we extracted the raw event data for the 2 (control vs experimental) by 2 (event vs no event) design, which we used to recompute the natural logarithm of the risk ratio and its standard error. The extracted event data is available at [osf.io/aykeh](https://osf.io/aykeh) and our analysis plan was preregistered at [osf.io/vnmzc](https://osf.io/vnmzc).

```{r, echo = FALSE}
options(scipen = 5)
suppressPackageStartupMessages(if(!require(metafor)){install.packages('metafor', repos = "http://cran.us.r-project.org")})
suppressPackageStartupMessages(library(metafor))
suppressPackageStartupMessages(if(!require(latex2exp)){install.packages('latex2exp', repos = "http://cran.us.r-project.org")})
suppressPackageStartupMessages(library(latex2exp))
suppressPackageStartupMessages(library(knitr))

x12 <- '../'
# x12 <- ''
bouri_data <- read.csv(sprintf('%sdata/bouri_data.csv', x12))

bouri_data$a <- bouri_data$control_n - bouri_data$control_events
bouri_data$b <- bouri_data$beta_n - bouri_data$beta_events
bouri_data$c <- bouri_data$control_events
bouri_data$d <- bouri_data$beta_event

bouri_data$beta_blocker <- c("atenolol",
                             "propanolol",
                             "metoprolol",
                             "metoprolol",
                             "metoprolol",
                             "atenolol",
                             "bisoprolol",
                             "metoprolol",
                             "metoprolol",
                             "bisoprolol",
                             "bisoprolol")

# Add .5 to studies with zero-counts
bouri_data[c(4, 7, 9), 7:10] <-  bouri_data[c(4, 7, 9), 7:10] + .5

bouri_data$ln_rr <- log((bouri_data$d/(bouri_data$b+bouri_data$d))/(bouri_data$c/(bouri_data$a+bouri_data$c)))
bouri_data$se_ln_rr <- sqrt((1/bouri_data$a)+(1/bouri_data$b)+(1/bouri_data$c)+(1/bouri_data$d))

mod_clean <- metafor::rma(yi = ln_rr,
                          sei = se_ln_rr,
                          method = "REML",
                          data = bouri_data[bouri_data$decrease == 0, ],
                          weighted = TRUE)
mod_dirty <- metafor::rma(yi = ln_rr,
                          sei = se_ln_rr,
                          method = "REML",
                          data = bouri_data[bouri_data$decrease == 1, ],
                          weighted = TRUE)
```

We computed the log risk ratio (i.e., log RR) for each study and pooled these using the `R` package `metafor` [@viechtbauer2010]. We estimated a weighted random-effects model using the restricted maximum-likelihood estimator (i.e., `REML`) [@viechtbauer2005] to estimate the variance of effects. We used the default weighting procedure in the `metafor` package. When there was a zero-count for a cell (e.g., zero events), 0.5 was added to that cell, as is common in meta-analyses on risk- and odds ratios in order to prevent computational artefacts [@agresti2002]. The 2014 meta-analysis [@bouri2014] did not specify the variance estimate used; hence, minor discrepancies between our estimates and the original estimates could be due to differences in the estimation procedure.

### Results

We were able to closely reproduce the estimates for the different sets of studies (Figure 2 of the 2014 meta-analysis [@bouri2014]). Bouri et al. differentiated between the estimates from the non-DECREASE trials and the DECREASE trials. We confirmed the effect size estimates and the variance estimates for both the non-DECREASE- and the DECREASE trials, save for some minor discrepancies due to the estimation method. Table 1 depicts the original and reproduced values for both sets of studies.

```{r echo=FALSE,results='asis'}
table1 <- matrix('', ncol = 5, nrow = 5)
table1[1,3] <- 'Risk ratio'
table1[1,4] <- '$\\tau^2$'
table1[1,5] <- 'Confidence interval'
table1[2,1] <- 'Non-DECREASE'
table1[4,1] <- 'DECREASE'
table1[c(2,4),2] <- 'Original'
table1[c(3,5),2] <- 'Reproduced'
table1[2,3] <- 1.27
table1[2,4] <- 0.00
table1[2,5] <- '[1.01; 1.60]'

table1[3,3] <- round(exp(mod_clean$b), 2)
table1[3,4] <- round(mod_clean$tau2, 2)
table1[3,5] <- sprintf('[%s; %s]', round(exp(mod_clean$ci.lb), 2), round(exp(mod_clean$ci.ub), 2))

table1[4,3] <- 0.42
table1[4,4] <- 0.29
table1[4,5] <- '[0.15; 1.23]'

table1[5,3] <- round(exp(mod_dirty$b), 2)
table1[5,4] <- round(mod_dirty$tau2, 2)
table1[5,5] <- sprintf('[%s; %s]', round(exp(mod_dirty$ci.lb), 2), round(exp(mod_dirty$ci.ub), 2))


knitr::kable(table1, caption = '__Table XX.__ The original- and reproduced meta-analytic results based on the data provided in the 2014 meta-analysis by Bouri et al.')
```

```{r, echo = FALSE}
mod_mods <- metafor::rma(yi = ln_rr,
                         sei = se_ln_rr,
                         mod =~ as.factor(decrease), # 1 are the decrease studies
                         method = "REML",
                         data = bouri_data,
                         weighted = TRUE)

i2_mods <- mod_mods$I2
```

Second, we meta-analyzed all studies combined, including a dummy predictor for the DECREASE and non-DECREASE studies to reproduce results presented in Figure 4 of the 2014 meta-analysis [@bouri2014]. Surprisingly, our results showed stronger evidence against equal subgroups than the original meta-analysis [@bouri2014] (original: $\chi^2(1)=3.91,p=.05$; reproduced: $\chi^2(1)=`r round(mod_mods$QM, 2)`,p=`r round(mod_mods$QMp, 3)`$). Additionally, the original analyses showed substantial residual heterogeneity ($I^2=74.4$\%) whereas we found no residual heterogeneity ($I^2=`r round(i2_mods, 3)`$\%). Different variance estimates (e.g., `DerSimonian-Laird` instead of `REML`) did not resolve this difference. We tried to clarify these discrepancies by e-mailing the original authors, but did not receive a response. Nonetheless, the broad strokes of the meta-regression confirmed that the DECREASE trials were the determining predictor for the effectiveness of beta-blockers (including DECREASE: $RR=`r round(exp(mod_mods$b[1] + mod_mods$b[2]), 3)`$; excluding DECREASE: $RR=`r round(exp(mod_mods$b[1]), 3)`$).
<!--- Emailed bouri about this on 2016 03 16 -->

```{r, echo = FALSE}
mod_mods_type <- metafor::rma(yi = ln_rr,
                         sei = se_ln_rr,
                         mod =~ as.factor(decrease) + as.factor(beta_blocker),
                         method = "REML",
                         data = bouri_data,
                         weighted = TRUE)
```

Additionally, and exploratively, we evaluated the predictive effect of the type of beta-blocker used in the trials. The DECREASE trials remain predictive of decreased mortality ($RR=`r round(exp(mod_mods_type$b[1] + mod_mods_type$b[2] + mod_mods_type$b[3]), 3)`$), <!-- DECREASE only uses bisoprolol! -->
whereas the non-DECREASE trials provide tentative, but uncertain, evidence that atenolol results in lower mortality ($RR=`r round(exp(mod_mods_type$b[1]), 3)`$). Nonetheless, for other beta-blockers in the non-DECREASE trials, there is still tentative and uncertain evidence that beta-blockers increase mortality (bisoprolol: $RR=`r round(exp(mod_mods_type$b[1] + mod_mods_type$b[3]), 3)`$; metoprolol: $RR=`r round(exp(mod_mods_type$b[1] + mod_mods_type$b[4]), 3)`$; propanolol: $RR=`r round(exp(mod_mods_type$b[1] + mod_mods_type$b[5]), 3)`$). Table 3 shows the meta-regression results in full.

```{r echo = FALSE}
table3 <- matrix(NA, nrow = 8, ncol = 3)
table3[1,1] <- ''
table3[2,1] <- 'Intercept'
table3[3,1] <- 'Non-DECREASE'
table3[4,1] <- 'DECREASE'
table3[5,1] <- 'Atenolol'
table3[6,1] <- 'Bisoprolol'
table3[7,1] <- 'Metoprolol'
table3[8,1] <- 'Propanolol'

table3[1,2] <- 'Estimate'
table3[2,2] <- round(mod_mods_type$b[1], 3)
table3[3,2] <- ''
table3[4,2] <- round(mod_mods_type$b[2], 3)
table3[5,2] <- ''
table3[6,2] <- round(mod_mods_type$b[3], 3)
table3[7,2] <- round(mod_mods_type$b[4], 3)
table3[8,2] <- round(mod_mods_type$b[5], 3)

table3[1,3] <- '95% CI'
table3[2,3] <- sprintf('%s; %s', round(mod_mods_type$ci.lb[1], 3),
                       round(mod_mods_type$ci.ub[1], 3))
table3[3,3] <- ''
table3[4,3] <- sprintf('%s; %s', round(mod_mods_type$ci.lb[2], 3),
                       round(mod_mods_type$ci.ub[2], 3))
table3[5,3] <- ''
table3[6,3] <- sprintf('%s; %s', round(mod_mods_type$ci.lb[3], 3),
                       round(mod_mods_type$ci.ub[3], 3))
table3[7,3] <- sprintf('%s; %s', round(mod_mods_type$ci.lb[4], 3),
                       round(mod_mods_type$ci.ub[4], 3))
table3[8,3] <- sprintf('%s; %s', round(mod_mods_type$ci.lb[5], 3),
                       round(mod_mods_type$ci.ub[5], 3))


knitr::kable(table3, caption = 'Meta-regression results for log(RR), including dummy predictors for DECREASE trials (reference: non-DECREASE trials) and type of beta-blockers used in the trial (reference: atenolol).')
```

## Step 2: evaluating the veracity of DECREASE studies

Based on the non-DECREASE estimates from Step 1, we estimated the probability of obtaining the results in the DECREASE trials. To this end, we assumed that the non-DECREASE trials provide a valid representation of the true effect of beta-blockers on perioperative mortality (similar to Bouri et al. [@bouri2014]). The estimated probability is also known as the veracity of the data [@peters2015], which indicates the probability of the observed data under a given true effect. We assumed that the non-DECREASE studies estimated the true effect distribution of perioperative beta-blockade on mortality, not perturbed by publication bias due to statistical (non)significance. Publication bias was assumed to not be a problem because a substantial number of nonsignificant effects are included in the dataset (9 of 11 results are nonsignificant).

### Method

```{r, echo = FALSE}
mod_clean_pred <- predict(mod_clean)
mod_dirty_pred <- predict(mod_dirty)
```

Based on the estimated mean log RR and its credible interval in the non-DECREASE studies, we computed the probability of the observed log RR in the DECREASE trials. The estimates of the non-DECREASE studies were obtained from Step 1, which include the estimated log RR (i.e., `r round(mod_clean$b, 2)`), and its 95\% credibility interval as provided by the package `metafor` (i.e., `r sprintf('[%s; %s]', round(mod_clean_pred$cr.lb, 3), round(mod_clean_pred$cr.ub, 3))`). The meta-analysis model assumes a normal distribution of population effects with the estimated effect as the mean of the distribution. The 95\% credibility interval denotes the bounds of the normal distribution that covers 95\% of the density, where the standard deviation is calculated as the distance from the mean to either bound, divided by 1.96. This allows for an approximation of the population effect distribution, as depicted in Figure `r fig <- 1; fig`. 

```{r, echo = FALSE}
temp <- seq(-3, 3, .001)

pdf(sprintf('%sfigures/fig1.pdf', x12), width = 8, height = 6)
par(mar = c(3,0,0,0))
plot(x = temp,
     dnorm(x = temp,
           mod_clean$b,
           (mod_clean_pred$pred - mod_clean_pred$cr.lb)/1.96),
     type = 'l',
     bty = 'n',
     # xaxt = 'n',
     yaxt = 'n',
     xlab = 'log(RR)',
     ylab = '')

points(x = bouri_data$ln_rr[bouri_data$decrease == 1][1], y = 0)
text(x = bouri_data$ln_rr[bouri_data$decrease == 1][1],
     y = .15,
     labels = 'DECREASE-I',
     cex = .8)

points(x = bouri_data$ln_rr[bouri_data$decrease == 1][2], y = 0)
text(x = bouri_data$ln_rr[bouri_data$decrease == 1][2] - .05,
     y = .15,
     labels = 'DECREASE-IV',
     cex = .8)

invisible(dev.off())
```

```{r figure 1, fig.cap = 'Density plot of the estimated true effect distribution based on the non-DECREASE studies only, with the position of the DECREASE studies highlighted.', out.width = '80%', fig.asp = .5, fig.align = 'center', echo = FALSE}
knitr::include_graphics(sprintf("%sfigures/fig1.pdf", x12))
```

Based on the estimated effect distribution from the non-DECREASE trials, we calculated the probability of each DECREASE trial result, or a more extreme result. In other words, we computed the *p*-value for the null hypothesis that the DECREASE trials arise from the same effect distribution as the non-DECREASE trials. This assumes that the information available from the other trials is informative of the true population effect. 

### Results

```{r, echo = FALSE}
prob <- pnorm(q = bouri_data$ln_rr[bouri_data$decrease == 1],
              mod_clean_pred$pred,
              (mod_clean_pred$pred - mod_clean_pred$cr.lb)/1.96) * 2
```

Figure `r fig` indicates that the DECREASE trials are highly unlikely under the estimated effect distribution based on the non-DECREASE trials. More specifically, the results from DECREASE-I (or more extreme) have a probability of $`r prob[1]`$ (less than 1 in a quintillion) and the results from DECREASE-IV have a probability of $`r prob[2]`$ (3 in a billion). This indicates the DECREASE trial results are unlikely to have come from the same population effect distribution as the non-DECREASE trials. Moreover, observing two of such extremely unlikely results jointly, as in the DECREASE trials, is nearly impossible, $`r prob[1]*prob[2]`$. Hence, this result indicates that the DECREASE trials are severely different from the non-DECREASE trials.

Results from Step 1 indicated that no between-trial variance (i.e., homogeneity; $\tau^2=0$) of the effects was observed; given the small number of trials included (i.e., `r mod_clean$k`) this estimate is uncertain, however. We conducted sensitivity analyses to see how dependent results are on the heterogeneity estimate. The probability of observing the DECREASE trials stays approximately below 1 out of 1000 until the variance estimate is 0.25; the probability stays approximately below 1 out of 100 until the variance estimate is 0.43 (see Figure `r fig <- fig + 1; fig`). To put these numbers into context, a variance of 0.25 would suggest that results of perioperative beta-blockade vary substantially even if perioperative beta-blockade has no effect whatsoever (RRs between `r round(exp(0 - .25), 3)` and `r round(exp(0 + .25), 3)` in 64\% of the cases) all due to contextual circumstances of the study.

```{r, echo = FALSE}
pdf(sprintf('%sfigures/fig2.pdf', x12), width = 8, height = 6)
tau2 <- seq(0, 2, .01)

prob_sens_t <- NULL
i <- 1

for (t2 in tau2){
  mod_clean_sens <- metafor::rma(yi = ln_rr,
                                 sei = se_ln_rr, tau2 = t2,
                                 method = "REML",
                                 data = bouri_data[bouri_data$decrease == 0, ],
                                 weighted = TRUE)
  mod_clean_pred_sens <- predict(mod_clean_sens)
  prob_sens <- pnorm(q = bouri_data$ln_rr[bouri_data$decrease == 1],
                     mod_clean_pred_sens$pred,
                     (mod_clean_pred_sens$pred - mod_clean_pred_sens$cr.lb)/1.96) * 2
  prob_sens_t[i] <- prob_sens[1] * prob_sens[2]
  
  i <- i + 1
}

par(mar = c(4, 4, 0, 0))
plot(tau2, prob_sens_t, type = 'l', xlab = TeX('$\\tau^2$'),
     ylab = 'p-value', bty = 'n')
points(x = tau2[c(26, 44)], y = prob_sens_t[c(26, 44)])
text(x = tau2[c(26, 44)],
     y = prob_sens_t[c(26, 44)] + .02,
     labels = c(TeX('$\\tau^2=.25$'), TeX('$\\tau^2=.43$')),
     cex = .8)
invisible(dev.off())
```
```{r figure 2, fig.cap = 'Sensitivity analyses for the p-value that indicates the probability of observing the results from the DECREASE studies, or more extreme results, based on the estimated true effect (non-DECREASE trials) and the accompanying variance estimate.', out.width = '80%', fig.asp = .5, fig.align = 'center', echo = FALSE}
knitr::include_graphics(sprintf("%sfigures/fig2.pdf", x12))
```

## Step 3: estimating the amount of fabricated data

```{r echo = FALSE}
# This is for easy reference
# And to easily include in text
iterations <- 10000
```
We estimated the number of data points that would need to be fabricated to arrive at the estimates from the DECREASE trials, given that the non-DECREASE trials represent the true effect of perioperative beta-blockade. In contrast to Step 2 this assumes that the DECREASE trials might in fact contain fabricated data. The estimates from Step 3 provide an indication of the extent of potential data fabrication in the DECREASE studies [@commissie2011;@commissie2012;@commissie2013;@bouri2014].

### Method

In order to estimate the number of fabricated data points, we first estimated the effect of perioperative beta-blockade on mortality (in log odds) in each trial arm. In total there are four trial arms: one per condition (beta-blocker or control) per trial type (DECREASE- and non-DECREASE trials). For each of these trial arms, we ran a meta-analysis applying the same methods used in Step 1. For each of the two DECREASE trials separately and the non-DECREASE trials combined, this resulted in four meta-analytic mortality estimates with corresponding effect variances (see Table 3; one estimate per cell). Throughout the simulations, we used the point estimates (i.e., fixed effect) to simulate genuine- and fabricated data, but supplemented this by using the more uncertain distribution estimates (i.e., random effects) as sensitivity analyses.

```{r echo=FALSE, results='asis'}
table2 <- matrix('', ncol = 3, nrow = 3)
table2[1,1] <- ''
table2[1,2] <- 'Dead'
table2[1,3] <- 'Alive'

table2[2,1] <- 'Beta-blockers'
table2[2,2] <- '$n_{11}$'
table2[2,3] <- '$n_{12}$'

table2[3,1] <- 'Control'
table2[3,2] <- '$n_{21}$'
table2[3,3] <- '$n_{22}$'

kable(table2, caption = 'Outcome possibilities within a simulated 2 (beta-blocker v control) by 2 (dead v alive) clinical trial.')
```

We applied the inversion method to estimate the number of fabricated data points in the DECREASE trials [@casella2002]. The inversion method iteratively hypothesizes that *X* out of *N* data points were fabricated (i.e., $X={0, 1, ..., N}$). For each combination of *X* and trial, we simulated `r iterations` datasets. Each simulated dataset contained *X* fabricated data points and *N-X* genuine data points. For each simulated dataset (exact simulation procedure in the next paragraph), we determined the likelihood of the results with 
\begin{equation}
\label{eq1}
L(\theta|\pi_{E},\pi_{C})=\pi_{E}^{n_{11}}(1-\pi_{E})^{n_{12}} \times \pi_{C}^{n_{21}}(1 - \pi_{C})^{n_{22}}
\end{equation}
where $\pi_{E}$ indicates the mortality rate in the beta-blocker condition as drawn from the meta-analytic effect distribution ($\pi_{C}$ indicates the mortality rate in the control condition). The likelihood was computed under both the fabricated effect estimates (i.e., $L_{fabricated}$) and the genuine data (i.e., $L_{genuine}$). Table 3 indicates which cell sizes the various $n_{XX}$ refer to within the (simulated) data. After computing the likelihoods, we compared them to determine whether the simulated data were more likely to arise from the genuine trials ($L_{genuine}>L_{fabricated}$) or from the fabricated trials ($L_{fabricated}>L_{genuine}$). Note that comparing the likelihoods is a minor deviation from the preregistration, where we initially planned on using $p$-value comparisons ([osf.io/vnmzc](https://osf.io/vnmzc)).

For each hypothesis of *X* out of *N* fabricated data points, we computed the probability that the fabricated data are more likely than the genuine data ($p_F=P(L_{fabricated}>L_{genuine})$).  Based on $p_F$, we computed the confidence interval for $X$ (i.e., $X_{LB};X_{UB}$). For a 95\% confidence interval, the lowerbound is equal to the $p_F$ closest to .025, whereas the upperbound is equal to the $p_F$ closest to .975.

We computed $p_F$ for all *X* out of *N* fabricated datapoints in `r iterations` randomly generated datasets, which were generated in three steps. For each dataset we: 

1. Sampled (across conditions, without replacement) *X* fictitious participants that would be the result of data fabrication. 

2. Determined the population mortality rate for each condition (i.e., for each cell as in Table 3). The meta-analytic point estimate was used or a population effect was randomly drawn from the meta-analytic effect distribution.

3. Simulated the number of deaths for the different conditions using a binomial distribution based on the mortality rate as determined in 2, resulting in the cell counts as in Table 3.

Based on the meta-analytic effect from 2 and the cell sizes from 3, we computed the  likelihoods $L_{fabricated}$ and $L_{genuine}$ using Equation \ref{eq1}. As mentioned before, we computed $p_F$, which indicated the probability that the data are more likely under the estimates resulting from the (allegedly) fabricated data (i.e., the DECREASE trials) than under the estimates resulting from the genuine data (i.e., the non-DECREASE trials; $p_F=P(L_{fabricated}>L_{genuine})$).

### Results

```{r, echo = FALSE}
# Log odds for control conditions
numerator <- bouri_data$c/(bouri_data$a + bouri_data$c)
denominator <- 1 - (bouri_data$c / (bouri_data$a + bouri_data$c))
bouri_data$ln_odds_cont <- log(numerator / denominator)

bouri_data$se_ln_odds_cont <- 1 / ((bouri_data$a + bouri_data$c) * 
                                     (bouri_data$c / (bouri_data$a + bouri_data$c)) *
                                     (1 - (bouri_data$c / (bouri_data$a + bouri_data$c))))

# Log odds for beta-blocker conditions
numerator <- bouri_data$d/(bouri_data$b + bouri_data$d)
denominator <- 1 - (bouri_data$d / (bouri_data$b + bouri_data$d))
bouri_data$ln_odds_beta <- log(numerator / denominator)

bouri_data$se_ln_odds_beta <- 1 / ((bouri_data$b + bouri_data$d) * 
                                     (bouri_data$d / (bouri_data$b + bouri_data$d)) *
                                     (1 - (bouri_data$d / (bouri_data$b + bouri_data$d))))

mod_cont <- rma(yi = ln_odds_cont,
                sei = se_ln_odds_cont,
                data = bouri_data[bouri_data$decrease == 0, ],
                method = 'REML',
                weighted = TRUE)
mod_beta <- rma(yi = ln_odds_beta,
                sei = se_ln_odds_beta,
                data = bouri_data[bouri_data$decrease == 0, ],
                method = 'REML',
                weighted = TRUE)

mod_cont_decrease <- rma(yi = ln_odds_cont,
                         sei = se_ln_odds_cont,
                         data = bouri_data[bouri_data$decrease == 1, ],
                         method = 'REML',
                         weighted = TRUE)
mod_beta_decrease <- rma(yi = ln_odds_beta,
                         sei = se_ln_odds_beta,
                         data = bouri_data[bouri_data$decrease == 1, ],
                         method = 'REML',
                         weighted = TRUE)

cont_pred <- predict(mod_cont)$pred
cont_cr_lb <- predict(mod_cont)$cr.lb
cont_cr_ub <- predict(mod_cont)$cr.ub
cont_var <- (cont_pred - cont_cr_lb) / 1.96

beta_pred <- predict(mod_beta)$pred
beta_cr_lb <- predict(mod_beta)$cr.lb
beta_cr_ub <- predict(mod_beta)$cr.ub
beta_var <- (beta_pred - beta_cr_lb) / 1.96

cont_decrease_pred <- predict(mod_cont_decrease)$pred
cont_decrease_cr_lb <- predict(mod_cont_decrease)$cr.lb
cont_decrease_cr_ub <- predict(mod_cont_decrease)$cr.ub
cont_decrease_var <- (cont_decrease_pred - cont_decrease_cr_lb) / 1.96

beta_decrease_pred <- predict(mod_beta_decrease)$pred
beta_decrease_cr_lb <- predict(mod_beta_decrease)$cr.lb
beta_decrease_cr_ub <- predict(mod_beta_decrease)$cr.ub
beta_decrease_var <- (beta_decrease_pred - beta_decrease_cr_lb) / 1.96

# Uncomment if you want to rerun the inversion method
# > t1
# [1] "2016-03-29 13:34:31 CEST"
# > t2
# [1] "2016-03-29 15:55:27 CEST"
# t1 <- Sys.time()
# set.seed(123)
# source('../functions/inversion_method_uncertain.R')
# # source('functions/inversion_method_uncertain.R')
# t2 <- Sys.time()
# set.seed(123)
# source('../functions/inversion_method_certain.R')
# # source('functions/inversion_method_certain.R')
# t3 <- Sys.time()

load('../data/result_almost_i_uncertain')
load('../data/result_almost_i_certain')

load('../data/result_almost_iv_uncertain')
load('../data/result_almost_iv_certain')

# load('data/result_almost_i_uncertain')
# load('data/result_almost_i_certain')
# 
# load('data/result_almost_iv_uncertain')
# load('data/result_almost_iv_certain')

res_i_uncertain <- result_almost_i_uncertain / iterations
res_i_certain <- result_almost_i_certain / iterations
  
res_iv_uncertain <- result_almost_iv_uncertain / iterations
res_iv_certain <- result_almost_iv_certain / iterations

res_i_uncertain_lb <- NULL
res_i_uncertain_ub <- NULL
res_i_certain_lb <- NULL
res_i_certain_ub <- NULL

res_iv_uncertain_lb <- NULL
res_iv_uncertain_ub <- NULL
res_iv_certain_lb <- NULL
res_iv_certain_ub <- NULL

j <- 1
for (i in seq(0, 1, .01))
{
  lb <- .5 - (i / 2)
  ub <- .5 + (i / 2)
  
  res_i_uncertain_lb[j] <- which(abs(res_i_uncertain - lb) == min(abs(res_i_uncertain - lb)))[1]
  res_i_uncertain_ub[j] <- which(abs(res_i_uncertain - ub) == min(abs(res_i_uncertain - ub)))[1]
  
  
  res_i_certain_lb[j] <- which(abs(res_i_certain - lb) == min(abs(res_i_certain - lb)))[1]
  res_i_certain_ub[j] <- which(abs(res_i_certain - ub) == min(abs(res_i_certain - ub)))[1]
  
  
  res_iv_uncertain_lb[j] <- which(abs(res_iv_uncertain - lb) == min(abs(res_iv_uncertain - lb)))[1]
  res_iv_uncertain_ub[j] <- which(abs(res_iv_uncertain - ub) == min(abs(res_iv_uncertain - ub)))[1]
  
  res_iv_certain_lb[j] <- which(abs(res_iv_certain - lb) == min(abs(res_iv_certain - lb)))[1]
  res_iv_certain_ub[j] <- which(abs(res_iv_certain - ub) == min(abs(res_iv_certain - ub)))[1]
  
  
  j <- j + 1
}

# Manually correct some errors in the bound seeking from the loop above
# errors arise from Monte Carlo error:
# .022 .021 .023 <-- selects .021, but should select 0
# considering that running >10000 takes ages and does not guarantee
# it will fix the problem, I do it like this
res_i_uncertain_lb <- ifelse(res_i_uncertain_lb == 4, 0, res_i_uncertain_lb)
res_i_certain_lb <- ifelse(res_i_certain_lb == 1, 0, res_i_certain_lb)
res_iv_uncertain_lb <- ifelse(res_iv_uncertain_lb == 8, 0, res_iv_uncertain_lb)
res_iv_certain_lb[98:101] <- 0
res_iv_certain_ub[98:101] <- 1067

pdf(sprintf('%sfigures/fig3.pdf', x12), width = 8, height = 6)

par(mar = c(5, 5, 2.5, 0),
    mfrow = c(2, 2))
plot(res_i_uncertain,
     xlab = 'Data points fabricated',
     ylab = 'Proportion',
     main = 'DECREASE-I',
     ylim = 0:1,
     type = 'l',
     lty = 1)
lines(res_i_certain, pch = 2, type = 'l', lty = 2)
abline(h = c(.025, .975), lty = 3)

legend(x = 0, y = .9, bty = 'n', lty = c(1, 2), legend = c("Distribution estimate", "Point estimate"))

par(mar = c(5, 0, 2.5, 0.5))

plot(res_iv_uncertain,
     xlab = 'Data-points fabricated',
     ylab = '',
     main = 'DECREASE-IV',
     ylim = 0:1,
     yaxt = 'n',
     type = 'l',
     lty = 1)
lines(res_iv_certain, pch = 2, type = 'l',
      lty = 2)
abline(h = c(.025, .975), lty = 3)

par(mar = c(4, 5, 0.5, 0))

plot(x = NA, y = NA,
     xlim = c(0,1), ylim = c(0, length(res_i_certain)),
     xlab = "Confidence in %", ylab = "Data points fabricated")

lines(x = seq(0, 1, .01), y = res_i_uncertain_lb)
lines(x = seq(0, 1, .01), y = res_i_uncertain_ub)
lines(x = seq(0, 1, .01), y = res_i_certain_lb, lty = 2, pch = 2, type = 'l')
lines(x = seq(0, 1, .01), y = res_i_certain_ub, lty = 2, pch = 2, type = 'l')
abline(v = .95, lty = 3)

# clip(x1 = 0, x2 = length(res_i_uncertain), y1 = 0.025, y2 = .975)
# abline(v = which(abs(res_i_uncertain - .975) == min(abs(res_i_uncertain - .975))), lty = 1)
# abline(v = which(abs(res_i_certain - .975) == min(abs(res_i_certain - .975))), lty = 2)

par(mar = c(4, 0, 0.5, 0.5))

plot(x = NA, y = NA,
     xlim = c(0,1), ylim = c(0, length(res_iv_certain)),
     xlab = "Confidence in %", ylab = "",
     yaxt = 'n')

lines(x = seq(0, 1, .01), y = res_iv_uncertain_lb)
lines(x = seq(0, 1, .01), y = res_iv_uncertain_ub)
lines(x = seq(0, 1, .01), y = res_iv_certain_lb, lty = 2, pch = 2, type = 'l')
lines(x = seq(0, 1, .01), y = res_iv_certain_ub, lty = 2, pch = 2, type = 'l')
abline(v = .95, lty = 3)
invisible(dev.off())
```

```{r figure 3, fig.cap = 'Inversion method results used to estimate the number of data points fabricated in the DECREASE-I and DECREASE-IV trials. The top row panels indicate $p_F$ (y-axis) for all $X$ out of $N$ fabricated data points (x-axis). The bottom row indicates the estimated number of fabricated data points (y-axis) when varying the degree of confidence (x-axis). Dotted lines indicate the bounds for a 95 percent CI.', out.width = '80%', fig.asp = .5, fig.align = 'center', echo = FALSE}
knitr::include_graphics(sprintf("%sfigures/fig3.pdf", x12))
```

For DECREASE-I ($N=`r bouri_data$control_n[10] + bouri_data$beta_n[10]`$), the 95\% confidence interval for the estimated number of fabricated data points is [`r which.min(res_i_certain - .025) - 1` - `r which.max(res_i_certain - .975) - 1`] or [`r which.min(res_i_uncertain - .025) - 1` - `r which.max(res_i_uncertain - .975) - 1`] when based on a point estimate or a more uncertain distribution estimate, respectively. The left column of Figure 3 depicts the $p_F$ per *X* fabricated data points (top panel) and the bounds of the confidence interval when the degree of confidence is altered (lower panel). Staying clearly between the dotted lines in the top panel, depicting the 95\% CI (top: .975; bottom: .025), it becomes apparent that the degree of uncertainty is too high to make any reasonable estimates about the number of fabricated data points with sufficient confidence. This is partly due to the small sample size of the DECREASE-I trial (i.e., $N=`r length(res_i_certain) - 1`$) and the availability of just the summary results. Only when the degree of confidence is lowered to around 75\% does the interval not span the entire sample size. As such, based on the summary results, little can be said about the extent of the data fabrication that occurred in the DECREASE-I trial, affirming the conclusions of the original committee report [@commissie2013]. 

For DECREASE-IV ($N=`r bouri_data$control_n[11] + bouri_data$beta_n[11]`$), the 95\% confidence interval for the estimated number of fabricated data points is [`r which.min(res_iv_certain - .025) - 1` - `r which.max(res_iv_certain - .975) - 1`] or [`r which.min(res_iv_uncertain - .025) - 1` - `r which.max(res_iv_uncertain - .975) - 1`] when based on a point estimate or a more uncertain distribution estimate, respectively. The relatively minor difference between the estimates indicates that there is a high degree of confidence that data fabrication did occur based on the difference of the trial results alone. Nonetheless, the range of potentially fabricated data points is still estimated at approximately 1000; this indicates that the summary results are insufficient to provide more than an estimated lowerbound. This indicates that it is possible not all data were fabricated (i.e., $N=`r length(res_iv_certain) - 1`$), increasing the importance of well-documented data provenance to discern between genuine and falsified data. This affirms the conclusion of the scientific integrity committee that the results of the DECREASE-IV trial are "scientifically incorrect" (p.11) [@commissie2012]. 

# Part 2:



# Discussion

The effect of beta-blockade on perioperative mortality was already unclear following the findings of scientific misconduct; these results strongly affirm that the DECREASE trials should be neglected when assessing the effectiveness of beta-blockers. Our results indicate that the results from the DECREASE trials are nearly impossible to have arisen from the same effect inspected by the non-DECREASE trials, except when we assume at least some of the data were manipulated. As such, the scientific validity of the DECREASE-I and DECREASE-IV trials should by now be clear: they are to be regarded as irrelevant when assessing the effectiveness of beta-blockade on perioperative mortality. Nonetheless, the original papers that presented these trial results are not yet retracted [@poldermans1999;@dunkelgrun2009], something we strongly recommend based on the combination of our results and the integrity reports [@commissie2011;@commissie2012;@commissie2013].

The ESC/ESA and ACC/AHA guidelines [@Kristensen_2014;@Fleisher_2014] on perioperative beta-blockade already excluded the DECREASE trials in their assessment, but also state that other trials by Poldermans are excluded. However, upon close inspection of the reference lists, the ACC/AHA guidelines still cites four trials as evidence base [@Boersma_2001;@poldermans1999;@van_Kuijk_2009;@Flu_2010], of which two were already inspected by the scientific integrity committees of Erasmus MC [@Boersma_2001;@poldermans1999]. In the ACC/AHA guidelines, the following is said about studies conducted by Poldermans: 

> _"If nonretracted DECREASE publications and/or other derivative studies by Poldermans are relevant to the topic, they can only be cited in the text with a comment about the finding compared with the current recommendation but should not form the basis of that recommendation or be used as a reference for the recommendation."_ [@Fleisher_2014]

Nonetheless, references _are_ made without clear comments. Given the confirmation of problems in the DECREASE-I and DECREASE-IV trials in our results, it stresses that there is reason to distrust trials by Poldermans. We pose that investigations should be initiated into works where Poldermans was clearly involved and which were not cleared by the scientific committees of Erasmus MC in their misconduct investigations. Especially those papers cited as evidence in the ACC/AHA guidelines should be investigated, considering they affect patients and their treatment directly.

Previously, further investigation of trials by Poldermans was deemed unfeasible due to the lack of raw data; here we indicate methods that do make it feasible. Based on just event-count data and comparable trials, we were able to estimate whether part of the data were in fact fabricated and whether the results were within reason of comparable trials. The results clearly indicated they were not.

The results of our analyses also highlight that, despite the lack of availability of the raw data, summary results from larger samples allow for better estimates of the number of fabricated data points when similar trials are available. Moreover, larger trials result in relatively more certainty (e.g., DECREASE-IV) about the estimated number of fabricated data points, when using the inversion method, compared to smaller trials (e.g., DECREASE-I). This increased certainty is due to decreased standard errors at the population level of the estimated effects, resulting in higher sensitivity to data anomalies. Nonetheless, much residual uncertainty remains and simply fewer  information is available in the summary results. Raw data availability would improve the options open to detect potential anomalies (note: raw data are available for DECREASE VI, but upon a freedom of information request Erasmus MC refused to share these data). The results also highlight that in order to prevent detection, it would be in the fabricators' interest to fabricate small studies even if raw data are hidden away (assuming the fabricator wants to remain undetected).

With respect to clinical practice, the results provide some tentative evidence that type of beta-blockade can severely influence perioperative mortality. Our reanalysis of the Bouri et al. [@bouri2014] data indicates that type of beta-blockade can reverse the effect on perioperative mortality, even after taking into account whether a study belongs to the DECREASE family. As such, atenolol seems to tentatively decrease perioperative mortality, whereas the others (metoprolol, propanolol, bisoprolol) increase perioperative mortality. However, there seems to be covariation with respect to treatment administration, duration, and dose, which further confounds whether the treatment effect is due to type of beta-blocker or due to one of these other parameters. This affirms the statement from the ESC/ESA guidelines that _"high priority needs to be given to new randomized clinical trials to better identify which patients derive benefit from beta-blocker therapy in the perioperative setting, and to determine the optimal method of beta-blockade"_ [@Kristensen_2014].

In sum, our research indicates that the DECREASE trials are nearly impossible and contain at least some manipulated data points. We recommend retraction of the DECREASE-I and DECREASE-IV trials, and recommend renewed investigations into Poldermans' work --- especially that work still referenced by guidelines on the use of beta-blockers. Moreover, it remains unclear whether beta-blockers might be effective given the right treatment. We recommend new and more extensively controlled, confirmatory trials to determine whether there is any use in administering beta-blockers in order to decrease perioperative mortality --- at the moment there is insufficient evidence to determine any useful effect of beta-blockers.


# References